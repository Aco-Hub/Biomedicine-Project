{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by exercises 8\n",
    "from abc import abstractmethod, ABC\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from IPython.display import clear_output\n",
    "#from backbones.fcnet import FCNet\n",
    "from fcnet import FCNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.prot.utils import get_samples_using_ic, check_min_samples, get_mode_ids, encodings, get_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaTemplate(nn.Module):\n",
    "    def __init__(self, backbone, n_way, n_support):\n",
    "        super(MetaTemplate, self).__init__()\n",
    "        self.n_way = n_way\n",
    "        self.n_support = n_support\n",
    "        self.n_query = -1  # (change depends on input)\n",
    "        self.feature = backbone\n",
    "        self.feat_dim = self.feature.final_feat_dim\n",
    "\n",
    "        # n_way = nb_classes per episode\n",
    "        # n_support = nb_samples per class for support set\n",
    "        # n_query = nb_samples per class for query set\n",
    "        # backbone = feature extractor (embedding network) ie. function f\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_forward(self, x, is_feature=False):\n",
    "        \"\"\"\n",
    "        forward pass, returns score (probabilities for query set)\n",
    "        output is logits for all query set (prob of each class)\n",
    "        first dim of output is n_way * n_query, nb of samples in query set\n",
    "        second dim is prob to belong to each class\n",
    "        x: [n_way, n_support + n_query, **embedding_dim]\n",
    "        out: [n_way * n_query, n_way]\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_forward_loss(self, x):\n",
    "        \"\"\"\n",
    "        takes the episode and compute loss of episode\n",
    "        x: [n_way, n_support + n_query, **embedding_dim]\n",
    "        out: loss (scalar)\n",
    "        \"\"\"\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.feature.forward(x)\n",
    "        return out\n",
    "\n",
    "    def parse_feature(self, x):\n",
    "        '''\n",
    "        create embeddings for support and query set\n",
    "        :param x: [n_way, n_support + n_query, **embedding_dim]\n",
    "        out: z_supp, z_queryÂ¨\n",
    "            z_supp: [n_way, n_support, feat_dim]\n",
    "            z_query: [n_way, n_query, feat_dim]\n",
    "        '''\n",
    "        x = Variable(x.to(self.device))\n",
    "        # reshape x to create one batch of size n_way * (n_support + n_query) and of dim whatever is dim of x\n",
    "        # x is of shape [n_way, n_support + n_query, **embedding_dim] originally, we have to reshape it to pass it to the NN ie. shape (batch_size, dim_size)\n",
    "        # note: x.contigous is used to make sure that is in the same place in mem (more efficient)\n",
    "        x = x.contiguous().view(self.n_way * (self.n_support + self.n_query), * x.size()[2:])\n",
    "        # Compute support and query feature.\n",
    "        z_all = self.forward(x)\n",
    "\n",
    "        # Reverse the transformation to distribute the samples based on the dimensions of their individual categories and flatten the embeddings.\n",
    "        # transformation is the transformation just above to one batch, ie. transform to original shape [n_way, n_support + n_query, **embedding_dim]\n",
    "        z_all = z_all.view(self.n_way, self.n_support + self.n_query, -1)\n",
    "\n",
    "        # Extract the support and query features.\n",
    "        z_support = z_all[:, :self.n_support, :]\n",
    "        z_query = z_all[:, self.n_support:, :]\n",
    "\n",
    "        return z_support, z_query\n",
    "\n",
    "    def correct(self, x):\n",
    "        # Compute the predictions scores.\n",
    "        scores = self.set_forward(x)\n",
    "\n",
    "        # Compute the top1 elements.\n",
    "        topk_scores, topk_labels = scores.data.topk(k=1, dim=1, largest=True, sorted=True)\n",
    "\n",
    "        # Detach the variables (transforming to numpy also detach the tensor)\n",
    "        topk_ind = topk_labels.cpu().numpy()\n",
    "\n",
    "        # Create the category labels for the queries, this is unique for the few shot learning setup\n",
    "        y_query = np.repeat(range(self.n_way), self.n_query)\n",
    "\n",
    "        #>>> np.repeat(range(10), 2)\n",
    "        #array([0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9])\n",
    "\n",
    "        # Compute number of elements that are correctly classified.\n",
    "        top1_correct = np.sum(topk_ind[:, 0] == y_query)\n",
    "        return float(top1_correct), len(y_query)\n",
    "\n",
    "    def train_loop(self, epoch, train_loader, optimizer):\n",
    "        print_freq = 10\n",
    "\n",
    "        avg_loss = 0\n",
    "        for i, (x, _) in enumerate(train_loader):\n",
    "            self.n_query = x.size(1) - self.n_support\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.set_forward_loss(x)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss = avg_loss + loss.item()\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                print('Epoch {:d} | Batch {:d}/{:d} | Loss {:f}'.format(epoch, i, len(train_loader),\n",
    "                                                                        avg_loss / float(i + 1)))\n",
    "        return avg_loss/len(train_loader)\n",
    "    \n",
    "    def test_loop(self, epoch, test_loader, record=None, return_std=False):\n",
    "        acc_all = []\n",
    "\n",
    "        iter_num = len(test_loader)\n",
    "        for i, (x, _) in enumerate(test_loader):\n",
    "            self.n_query = x.size(1) - self.n_support\n",
    "            correct_this, count_this = self.correct(x)\n",
    "            acc_all.append(correct_this / count_this * 100)\n",
    "\n",
    "        acc_all = np.asarray(acc_all)\n",
    "        acc_mean = np.mean(acc_all)\n",
    "        acc_std = np.std(acc_all)\n",
    "        print(f'Epoch {epoch} | Test Acc = {acc_mean:4.2f}% +- {1.96 * acc_std / np.sqrt(iter_num):4.2f}%')\n",
    "\n",
    "        if return_std:\n",
    "            return acc_mean, acc_std\n",
    "        else:\n",
    "            return acc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLoss, self).__init__()\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, inputs, targets): # inputs: torch.Size([75, 59, 64]), targets: torch.Size([75])\n",
    "        inputs = inputs.view(inputs.size(0), inputs.size(1), -1)\n",
    "        # inputs: torch.Size([75, 59, 64])\n",
    "        log_probs = self.logsoftmax(inputs)\n",
    "\n",
    "        # below = problematic line\n",
    "        # torch zeros (75, 59)\n",
    "        targets = torch.zeros(inputs.size(0), inputs.size(1)).scatter_(1, targets.unsqueeze(1).data.cpu(), 1)\n",
    "        targets = targets.unsqueeze(-1)\n",
    "        targets = targets.cuda()\n",
    "        loss = (- targets * log_probs).mean(0).sum() \n",
    "        return loss / inputs.size(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can network 1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is modified from https://github.com/blue-blue272/fewshot-CAN\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from methods.meta_template import MetaTemplate\n",
    "\n",
    "\n",
    "class CanNet(MetaTemplate):\n",
    "    def __init__(self, backbone, n_way, n_support, reduction_ratio=6, temperature=0.025, scale_cls=7, num_classes=7195):\n",
    "        super(CanNet, self).__init__(backbone, n_way, n_support)\n",
    "        self.m = self.feat_dim\n",
    "        self.loss_fn = CrossEntropyLoss()\n",
    "        self.num_classes = num_classes\n",
    "        #self.linear = nn.Linear(self.m, n_way)\n",
    "        #self.linear = nn.Linear(self.m, self.num_classes)\n",
    "        self.linear = nn.Linear(1, self.num_classes)\n",
    "        self.fusion_conv = nn.Conv1d(self.feat_dim, 1, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm1d(int(self.feat_dim / reduction_ratio))\n",
    "        self.w1 = nn.Linear(self.m, int(self.m / reduction_ratio))\n",
    "        self.activation = nn.ReLU()\n",
    "        self.w2 = nn.Linear(int(self.m / reduction_ratio), self.m)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.temperature = temperature\n",
    "        self.scale_cls = scale_cls\n",
    "\n",
    "    def set_forward(self, x, is_feature=False):\n",
    "        z_support, z_query = self.parse_feature(x, is_feature)\n",
    "\n",
    "        z_support = z_support.contiguous()\n",
    "        z_proto = z_support.view(self.n_way, self.n_support, self.m).mean(1)  # the shape of z is [n_data, n_dim]\n",
    "        z_query = z_query.contiguous().view(self.n_way * self.n_query, self.m)\n",
    "        z_proto_attention = torch.zeros((self.n_support,self.n_way * self.n_query, self.m)).cuda() # shape: [n_way , n-query, n_dim]\n",
    "        z_query_attention = torch.zeros((self.n_support,self.n_way * self.n_query, self.m)).cuda() # shape: [n_way , n_query, n_dim]\n",
    "        z_proto_attention, z_query_attention = self.cross_attention_module(z_proto, z_query)\n",
    "        ftrain = z_proto_attention # torch.Size([5, 75, 64])\n",
    "        ftest = z_query_attention #torch.Size([5, 75, 64])\n",
    "\n",
    "        ftrain = ftrain.mean(2) # torch.Size([5, 75])\n",
    "\n",
    "        #ftrain = ftrain.T # torch.Size([75, 5])\n",
    "        #ftest = ftest.transpose(0, 1) # torch.Size([75, 5, 64])\n",
    "\n",
    "        if not self.training:\n",
    "            return self.test(ftrain, ftest)\n",
    "    \n",
    "        # Normalize ftest and ftrain along the feature dimension\n",
    "        #ftest_norm = F.normalize(ftest, p=2, dim=1, eps=1e-12) # torch.Size([5, 75, 64]\n",
    "        #ftrain_norm = F.normalize(ftrain, p=2, dim=1, eps=1e-12) # torch.Size([5, 75])    \n",
    "\n",
    "        ftrain = ftrain.unsqueeze(2) # torch.Size([5, 75, 1])\n",
    "        # Calculate cls_scores by taking the matrix product of ftest_norm and ftrain_norm (transposed)\n",
    "        #cls_scores = self.scale_cls * torch.sum(ftest_norm * ftrain_norm, dim=2) # torch.Size([5, 64])\n",
    "        cls_scores = ftest * ftrain\n",
    "        cls_scores = cls_scores.transpose(0, 1)\n",
    "        #cls_scores = cls_scores.view(self.n_way * self.n_query, self.n_way)\n",
    "\n",
    "        return cls_scores, ftest\n",
    "    \n",
    "    def set_forward_loss(self, x, y_true_query):\n",
    "        y_query = torch.from_numpy(np.repeat(range( self.n_way ), self.n_query ))\n",
    "        y_query = Variable(y_query.cuda())\n",
    "\n",
    "\n",
    "        def one_hot(labels_train):\n",
    "            \"\"\"\n",
    "            Turn the labels_train to one-hot encoding.\n",
    "            Args:\n",
    "                labels_train: [batch_size, num_train_examples]\n",
    "            Return:\n",
    "                labels_train_1hot: [batch_size, num_train_examples, K]\n",
    "            \"\"\"\n",
    "            labels_train = labels_train.cpu()\n",
    "            nKnovel = 1 + labels_train.max()\n",
    "            labels_train_1hot_size = list(labels_train.size()) + [nKnovel,]\n",
    "            labels_train_unsqueeze = labels_train.unsqueeze(dim=labels_train.dim())\n",
    "            labels_train_1hot = torch.zeros(labels_train_1hot_size).scatter_(len(labels_train_1hot_size) - 1, labels_train_unsqueeze, 1)\n",
    "            return labels_train_1hot\n",
    "\n",
    "        y_query_one_hot = one_hot(y_query).cuda()\n",
    "\n",
    "        cls_scores, ftest = self.set_forward(x)\n",
    "\n",
    "        # ftest is of shape (5, 75, 64), change it to (1, 75, 64, 5) to be able to do matmul\n",
    "        ftest = ftest.unsqueeze(0) # torch.Size([1, 5, 75, 64])\n",
    "        ftest = ftest.transpose(2, 3) # torch.Size([1, 5, 64, 75])\n",
    "        ftest = ftest.transpose(1, 3) # torch.Size([1, 75, 64, 5])\n",
    "\n",
    "        # computation for the second loss\n",
    "\n",
    "\n",
    "        # this matmul is incorrect should be ftest: (1, 75, 64, 5) and y_query_one_hot: (1, 75, 5, 1)\n",
    "        y_query_one_hot = y_query_one_hot.unsqueeze(0) # torch.Size([1, 5, 75, 5])\n",
    "        y_query_one_hot = y_query_one_hot.unsqueeze(3) # torch.Size([1, 5, 75, 5, 1])\n",
    "        ftest = torch.matmul(ftest, y_query_one_hot) # torch.Size([1, 75, 64, 1])\n",
    "        ftest = ftest.view(-1, self.m) # torch.Size([75, 64])\n",
    "\n",
    "        ftest = ftest.unsqueeze(2) # torch.Size([75, 64, 1])\n",
    "\n",
    "        # goal: ytest = (75, 59, 64)\n",
    "        ytest = self.linear(ftest) # torch.Size([75, 64, 59])\n",
    "        ytest = ytest.transpose(2, 1) # torch.Size([75, 59, 64])\n",
    "\n",
    "        # cls scores: torch.Size([75, 5, 64]), y_query: torch.Size([75])\n",
    "        l1 = self.loss_fn(cls_scores, y_query )\n",
    "\n",
    "        y_true_query = y_true_query.reshape(-1) #torch.Size([75])\n",
    "        l2 = self.loss_fn(ytest, y_true_query)\n",
    "        loss = (l1 + l2) / 2\n",
    "        \n",
    "\n",
    "        return loss\n",
    "\n",
    "    \"\"\"\n",
    "    def set_forward_loss(self, x, y_true_query):\n",
    "        y_query = torch.from_numpy(np.repeat(range( self.n_way ), self.n_query ))\n",
    "        y_query = Variable(y_query.cuda())\n",
    "\n",
    "        cls_scores, ftest = self.set_forward(x)\n",
    "\n",
    "        y_true_query = y_true_query.contiguous().view(-1)\n",
    "        criterion = CrossEntropyLoss()\n",
    "        l1 = criterion(cls_scores, y_query)\n",
    "        loss = l1\n",
    "        \n",
    "\n",
    "        return loss\n",
    "    \"\"\"\n",
    "    def fusion_layer(self, z):\n",
    "        \"\"\"\n",
    "        Generates cross attention map A\n",
    "        :param R: [n_dim,n_dim]\n",
    "        :return: A  [n_dim]\n",
    "        \"\"\"\n",
    "\n",
    "        GAP = torch.mean(z, dim=-2)\n",
    "\n",
    "        w = self.w2(self.activation(self.w1(GAP)))\n",
    "\n",
    "\n",
    "        fusion = z * w.unsqueeze(2)\n",
    "\n",
    "        conv = torch.mean(fusion,dim=-1)\n",
    "\n",
    "        A = self.softmax(conv/self.temperature)\n",
    "\n",
    "        return A\n",
    "\n",
    "    def cross_attention_module(self, z_support, z_query):\n",
    "        \"\"\"\n",
    "        TODO: do this operation for all pairs at once instead of looping, look at base code\n",
    "        Takes 1 support embedding and 1 query embedding and returns cross-attentioned embeddings\n",
    "        :param z_support: [n_dim]\n",
    "        :param z_query: [n_dim]\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        def correlation_layer(z_support, z_query): \n",
    "            \"\"\"\n",
    "            Takes 1 support embedding and 1 query embedding and returns correlation map\n",
    "            ie. P and Q in the paper. P is [P1, P2, ..., Pn] where n is the dimension of the embeddings, same for Q.\n",
    "            :param z_support: [n_dim] ie. P\n",
    "            :param z_query: [n_dim] ie. Q\n",
    "            :return: correlation_map: [n_dim, n_dim]. Note: we use R^q = correlation_map and R^p = correlation_map.T \n",
    "            \"\"\"\n",
    "\n",
    "            # compute cosine similarity between support and query embeddings\n",
    "            #print(\"z_support_shape\", z_support.shape)\n",
    "            #print(\"z_query_shape\", z_query.shape)\n",
    "\n",
    "            #P = z_support / torch.linalg.norm(z_support, ord=2)\n",
    "            #Q = z_query / torch.linalg.norm(z_query, ord=2)\n",
    "            #P = F.normalize(z_support, p=2, dim=-1, eps=1e-12)\n",
    "            #Q = F.normalize(z_query, p=2, dim=-1, eps=1e-12)\n",
    "            P = z_support\n",
    "            Q = z_query\n",
    "\n",
    "            #print(\"P shape after norm\", P.shape)\n",
    "            #print(\"Q shape after norm\", Q.shape)\n",
    "            # P is of dim (n_dim) and Q is of dim (ndim)\n",
    "            # we need to change P to (n_dim, 1) and Q to (ndim, 1)\n",
    "            #P = P.reshape(P.shape, 1)\n",
    "            #Q = Q.reshape(Q.shape, 1)\n",
    "            #print(\"P shape after reshape\", P.shape)\n",
    "            #print(\"Q shape after reshape\", Q.shape)\n",
    "            correlation_map = torch.einsum(\"ij,kl->ikjl\",P,Q)  # dim: [n_dim, n_dim]\n",
    "            #print(\"correlation shape\", correlation_map.shape)\n",
    "\n",
    "            return correlation_map\n",
    "\n",
    "        P_k = z_support\n",
    "        Q_b = z_query\n",
    "\n",
    "        # compute correlation map\n",
    "        R_p = correlation_layer(P_k, Q_b)\n",
    "        R_q = R_p.transpose(2, 3)\n",
    "\n",
    "        # compute fusion layer\n",
    "        A_p = self.fusion_layer(R_p)\n",
    "        A_q = self.fusion_layer(R_q)\n",
    "\n",
    "        \"\"\"\n",
    "        A_p = A_p * P_k\n",
    "        P_bk = A_p + P_k\n",
    "\n",
    "        A_q = A_q * Q_b\n",
    "        Q_bk = A_q + Q_b\n",
    "        \"\"\"\n",
    "        P_bk = P_k.unsqueeze(1) * (1 + A_p)\n",
    "        Q_bk = Q_b.unsqueeze(0) * (1 + A_q)\n",
    "\n",
    "        return P_bk, Q_bk\n",
    "    \n",
    "    def correct_old(self, x):\n",
    "        scores = self.set_forward(x)\n",
    "        y_query = np.repeat(range(self.n_way), self.n_query)\n",
    "\n",
    "        topk_scores, topk_labels = scores.data.topk(k=1, dim=1, largest=True, sorted=True)\n",
    "        topk_ind = topk_labels.cpu().numpy()\n",
    "        top1_correct = np.sum(topk_ind[:, 0] == y_query)\n",
    "        return float(top1_correct), len(y_query)\n",
    "    \n",
    "    def correct(self, x):\n",
    "        \"\"\"\n",
    "        Testing new correct function\n",
    "        \"\"\"\n",
    "        scores = self.set_forward(x)\n",
    "        y_query = np.repeat(range(self.n_way), self.n_query)\n",
    "        _, preds = torch.max(scores.detach().cpu(), 1)\n",
    "        correct_preds = torch.eq(torch.from_numpy(y_query), preds)\n",
    "        num_correct = torch.sum(correct_preds).float()\n",
    "        return num_correct, len(y_query)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def train_loop(self, epoch, train_loader, optimizer):\n",
    "        print_freq = 10\n",
    "\n",
    "        avg_loss = 0\n",
    "        self.train()\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            y_all = y.cuda()\n",
    "    \n",
    "            # y true query is the global labels for the query set\n",
    "            y_true_query = y_all[:, self.n_support:]\n",
    "\n",
    "            self.n_query = x.size(1) - self.n_support\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.set_forward_loss(x, y_true_query)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss = avg_loss + loss.item()\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                print('Epoch {:d} | Batch {:d}/{:d} | Loss {:f}'.format(epoch, i, len(train_loader),\n",
    "                                                                        avg_loss / float(i + 1)))\n",
    "        return avg_loss/len(train_loader)\n",
    "    \n",
    "    def test_loop(self, epoch, test_loader, record=None, return_std=False):\n",
    "        acc_all = []\n",
    "\n",
    "        iter_num = len(test_loader)\n",
    "\n",
    "        self.eval()\n",
    "        for i, (x, _) in enumerate(test_loader):\n",
    "            self.n_query = x.size(1) - self.n_support\n",
    "            correct_this, count_this = self.correct(x)\n",
    "            acc_all.append(correct_this / count_this * 100)\n",
    "\n",
    "        acc_all = np.asarray(acc_all)\n",
    "        acc_mean = np.mean(acc_all)\n",
    "        acc_std = np.std(acc_all)\n",
    "        print(f'Epoch {epoch} | Test Acc = {acc_mean:4.2f}% +- {1.96 * acc_std / np.sqrt(iter_num):4.2f}%')\n",
    "\n",
    "        if return_std:\n",
    "            return acc_mean, acc_std\n",
    "        else:\n",
    "            return acc_mean\n",
    "        \n",
    "    def test(self, ftrain, ftest):\n",
    "        #print(\"using this function\")\n",
    "\n",
    "        ftest = ftest.mean(2)\n",
    "        #ftest = F.normalize(ftest, p=2, dim=1, eps=1e-12)\n",
    "        #ftrain = F.normalize(ftrain, p=2, dim=1, eps=1e-12)\n",
    "        #print(\"ftrain: \", ftrain.shape)\n",
    "        #print(\"ftest: \", ftest.shape)\n",
    "        #ftrain:  torch.Size([5, 75])\n",
    "        #ftest:  torch.Size([5, 75])\n",
    "        \n",
    "\n",
    "        #scores = self.scale_cls * torch.sum(ftest * ftrain, dim=0)\n",
    "        #print(\"scores: \", scores.shape)\n",
    "        scores = ftest * ftrain\n",
    "\n",
    "        scores = scores.view(self.n_way * self.n_query, self.n_way)\n",
    "        \n",
    "        return scores\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Special class for few-shot dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.check_init()\n",
    "\n",
    "    def check_init(self):\n",
    "        \"\"\"\n",
    "        Convenience function to check that the FewShotDataset is properly configured.\n",
    "        \"\"\"\n",
    "        required_attrs = ['_dataset_name', '_data_dir']\n",
    "        for attr in required_attrs:\n",
    "            if not hasattr(self, attr):\n",
    "                raise ValueError(f'FewShotDataset must have attribute {attr}.')\n",
    "\n",
    "        if not os.path.exists(self._data_dir):\n",
    "            raise ValueError(\n",
    "                f'{self._data_dir} does not exist yet. Please generate/download the dataset first.')\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def __getitem__(self, i):\n",
    "        return NotImplemented\n",
    "\n",
    "    @abstractmethod\n",
    "    def __len__(self):\n",
    "        return NotImplemented\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def dim(self):\n",
    "        return NotImplemented\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_data_loader(self, mode='train') -> DataLoader:\n",
    "        return NotImplemented\n",
    "\n",
    "    @property\n",
    "    def dataset_name(self):\n",
    "        \"\"\"\n",
    "        A string that identifies the dataset, e.g., 'swissprot'\n",
    "        \"\"\"\n",
    "        return self._dataset_name\n",
    "\n",
    "    @property\n",
    "    def data_dir(self):\n",
    "        return self._data_dir\n",
    "\n",
    "    def initialize_data_dir(self, root_dir):\n",
    "        os.makedirs(root_dir, exist_ok=True)\n",
    "        #self._data_dir = os.path.join(root_dir, self._dataset_name)\n",
    "        self._data_dir = \"data/swissprot\"\n",
    "\n",
    "class SPDataset(FewShotDataset, ABC):\n",
    "    _dataset_name = 'swissprot'\n",
    "\n",
    "    def load_swissprot(self, level = 5, mode='train', min_samples = 20):\n",
    "        samples = get_samples_using_ic(root = self.data_dir)\n",
    "        samples = check_min_samples(samples, min_samples)\n",
    "        unique_ids = set(get_mode_ids(samples)[mode])\n",
    "        return [sample for sample in samples if sample.annot in unique_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTDIM = 1280\n",
    "\n",
    "class SubDataset(Dataset):\n",
    "    def __init__(self, samples, data_dir):\n",
    "        self.samples = samples\n",
    "        self.encoder = encodings(data_dir)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sample = self.samples[i]\n",
    "        return sample.input_seq, self.encoder[sample.annot]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return PROTDIM\n",
    "\n",
    "class EpisodicBatchSampler(object):\n",
    "    def __init__(self, n_classes, n_way, n_episodes):\n",
    "        self.n_classes = n_classes\n",
    "        self.n_way = n_way\n",
    "        self.n_episodes = n_episodes\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_episodes\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(self.n_episodes):\n",
    "            yield torch.randperm(self.n_classes)[:self.n_way]\n",
    "\n",
    "class SPSetDataset(SPDataset):\n",
    "    def __init__(self, n_way, n_support, n_query, n_episode=100, root='./data', mode='train'):\n",
    "        self.initialize_data_dir(root)\n",
    "\n",
    "        self.n_way = n_way\n",
    "        self.n_episode = n_episode\n",
    "        min_samples = n_support + n_query\n",
    "        self.encoder = encodings(self.data_dir)\n",
    "\n",
    "        # check if samples_all.pkl exists\n",
    "        if os.path.exists('samples_all.pkl'):\n",
    "            # load samples_all using pickle\n",
    "            with open('samples_all.pkl', 'rb') as f:\n",
    "                samples_all = pickle.load(f)\n",
    "        else:\n",
    "            samples_all = self.load_swissprot(mode = mode, min_samples = min_samples)\n",
    "\n",
    "            # save samples_all using pickle\n",
    "            with open('samples_all.pkl', 'wb') as f:\n",
    "                pickle.dump(samples_all, f)\n",
    "            \n",
    "\n",
    "\n",
    "        self.categories = get_ids(samples_all) # Unique annotations\n",
    "        self.x_dim = PROTDIM\n",
    "\n",
    "        self.sub_dataloader = []\n",
    "\n",
    "        sub_data_loader_params = dict(batch_size=min_samples,\n",
    "                                      shuffle=True,\n",
    "                                      num_workers=0,  # use main thread only or may receive multiple batches\n",
    "                                      pin_memory=False)\n",
    "\n",
    "        # Create the sub datasets for each annotation of the categories and collect all the dataloaders in `self.sub_dataloader`.\n",
    "        for annotation in self.categories:\n",
    "            samples = [sample for sample in samples_all if sample.annot == annotation]\n",
    "            sub_dataset = SubDataset(samples, self.data_dir)\n",
    "            self.sub_dataloader.append(torch.utils.data.DataLoader(sub_dataset, **sub_data_loader_params))\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return next(iter(self.sub_dataloader[i]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.categories)\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self.x_dim\n",
    "\n",
    "    def get_data_loader(self) -> DataLoader:\n",
    "        sampler = EpisodicBatchSampler(len(self), self.n_way, self.n_episode)\n",
    "        data_loader_params = dict(batch_sampler=sampler, num_workers=0, pin_memory=True)\n",
    "        \n",
    "        # check if data_loader.pkl exists\n",
    "        if os.path.exists('data_loader.pkl'):\n",
    "            # load data_loader using pickle\n",
    "            with open('data_loader.pkl', 'rb') as f:\n",
    "                data_loader = pickle.load(f)\n",
    "        else:\n",
    "            data_loader = torch.utils.data.DataLoader(self, **data_loader_params)\n",
    "        \n",
    "            # save data_loader using pickle\n",
    "            with open('data_loader.pkl', 'wb') as f:\n",
    "                pickle.dump(data_loader, f)\n",
    "        return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_way, n_support, n_query, n_train_episode):\n",
    "    # Load train dataset. Remember to use make use of functions defined in the `SPSetDataset`.\n",
    "    \n",
    "    if os.path.exists('train_dataset.pkl'):\n",
    "        # load train_dataset using pickle\n",
    "        with open('train_dataset.pkl', 'rb') as f:\n",
    "            train_dataset = pickle.load(f)\n",
    "    else:\n",
    "        train_dataset = SPSetDataset(n_way, n_support, n_query, n_episode=n_train_episode, root='./data', mode='train')\n",
    "        # save as pickle\n",
    "        with open('train_dataset.pkl', 'wb') as f:\n",
    "            pickle.dump(train_dataset, f)\n",
    "    train_loader = train_dataset.get_data_loader()\n",
    "\n",
    "    # Load test dataset. Remember to use make use of functions defined in the `SPSetDataset`.\n",
    "    if os.path.exists('test_dataset.pkl'):\n",
    "        # load test_dataset using pickle\n",
    "        with open('test_dataset.pkl', 'rb') as f:\n",
    "            test_dataset = pickle.load(f)\n",
    "    else:\n",
    "        test_dataset = SPSetDataset(n_way, n_support, n_query, n_episode=100, root='./data', mode='test')\n",
    "        # save as pickle\n",
    "        with open('test_dataset.pkl', 'wb') as f:\n",
    "            pickle.dump(test_dataset, f)\n",
    "    test_loader =  test_dataset.get_data_loader()\n",
    "\n",
    "    # Initialize a fully connected network `FCNet` in `fcnet.py` with two hidden layers of 512 units each as feature extractor.\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    backbone = FCNet(train_dataset.dim).to(device)\n",
    "\n",
    "\n",
    "    # Initialize model using the backbone and the optimizer.\n",
    "    model = CanNet(backbone, n_way, n_support).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    test_accs = []; train_losses = []\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "\n",
    "        # Implement training of the model. Remember to make use of functions defined in the `ProtoNet` and `MetaTemplate` class.\n",
    "        epoch_loss = model.train_loop(epoch, train_loader, optimizer)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        # Evaluate test performance for epoch. Remember to make use of functions defined in the `ProtoNet` and `MetaTemplate` class.\n",
    "        test_acc = model.test_loop(epoch, test_loader)\n",
    "        test_accs.append(test_acc)\n",
    "        print(f'Epoch {epoch} | Train Loss {epoch_loss} | Test Acc {test_acc}')\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 2.5))\n",
    "    ax1.plot(range(len(train_losses)), train_losses)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Train Loss')\n",
    "    ax1.grid()\n",
    "\n",
    "    ax2.plot(range(len(test_accs)), test_accs)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Test Accuracy')\n",
    "    ax2.grid()\n",
    "    fig.suptitle(f\"n_way={n_way}, n_support={n_support}, n_query={n_query}, n_train_episode={n_train_episode}\")\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_way': 5, 'n_support': 5, 'n_query': 15, 'n_train_episode': 5}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Batch 0/5 | Loss 5.351523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/marluxiaboss/anaconda3/envs/fewshotbench/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_vars.py\", line 624, in change_attr_expression\n",
      "    value = eval(expression, frame.f_globals, frame.f_locals)\n",
      "  File \"<string>\", line 1\n",
      "    tensor([[0.0036, 0.0038, 0.0035, 0.0035, 0.0034, 0.0025, 0.0035, 0.0043, 0.0026,         0.0026, 0.0043, 0.0044, 0.0034, 0.0028, 0.0034, 0.0030, 0.0030, 0.0030,         0.0028, 0.0029, 0.0028, 0.0029, 0.0035, 0.0029, 0.0029, 0.0033, 0.0033,         0.0030, 0.0029, 0.0030, 0.0027, 0.0027, 0.0035, 0.0035, 0.0029, 0.0028,         0.0034, 0.0027, 0.0028, 0.0027, 0.0034, 0.0033, 0.0030, 0.0029, 0.0037,         0.0033, 0.0036, 0.0037, 0.0033, 0.0029, 0.0032, 0.0032, 0.0027, 0.0030,         0.0031, 0.0029, 0.0036, 0.0033, 0.0032, 0.0042, 0.0026, 0.0026, 0.0027,         0.0027, 0.0027, 0.0026, 0.0027, 0.0026, 0.0027, 0.0027, 0.0027, 0.0026,         0.0030, 0.0026, 0.0027],        [0.0029, 0.0031, 0.0028, 0.0028, 0.0028, 0.0020, 0.0028, 0.0035, 0.0021,         0.0021, 0.0035, 0.0036, 0.0027, 0.0023, 0.0027, 0.0024, 0.0024, 0.0024,         0.0022, 0.0023, 0.0023, 0.0024, 0.0028, 0.0023, 0.0023, 0.0027, 0.0026,         0.0024, 0.0023, 0.0024, 0.0022, 0.0022, 0.0028, 0.0029, 0.0024, 0.0022,         0.0027, 0.0022, 0.0022, 0.0022, 0.0028, 0.0027, 0.0024, 0.0024, 0.0029,         0.0026, 0.0029, 0.0030, 0.0027, 0.0023, 0.0026, 0.0025, 0.0022, 0.0024,         0.0025, 0.0023, 0.0029, 0.0027, 0.0026, 0.0033, 0.0021, 0.0021, 0.0022,         0.0022, 0.0022, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021, 0.0022, 0.0021,         0.0024, 0.0021, 0.0021],        [0.0028, 0.0030, 0.0028, 0.0028, 0.0027, 0.0020, 0.0028, 0.0034, 0.0021,         0.0021, 0.0034, 0.0035, 0.0027, 0.0022, 0.0027, 0.0024, 0.0024, 0.0023,         0.0022, 0.0023, 0.0022, 0.0023, 0.0028, 0.0023, 0.0023, 0.0026, 0.0026,         0.0023, 0.0023, 0.0024, 0.0022, 0.0021, 0.0028, 0.0028, 0.0023, 0.0022,         0.0027, 0.0021, 0.0022, 0.0022, 0.0027, 0.0026, 0.0024, 0.0023, 0.0029,         0.0026, 0.0028, 0.0029, 0.0027, 0.0023, 0.0026, 0.0025, 0.0022, 0.0024,         0.0024, 0.0023, 0.0029, 0.0026, 0.0026, 0.0033, 0.0020, 0.0021, 0.0021,         0.0021, 0.0022, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021,         0.0024, 0.0021, 0.0021],        [0.0028, 0.0030, 0.0028, 0.0028, 0.0027, 0.0020, 0.0028, 0.0034, 0.0021,         0.0021, 0.0034, 0.0035, 0.0027, 0.0022, 0.0027, 0.0024, 0.0024, 0.0023,         0.0022, 0.0023, 0.0023, 0.0023, 0.0028, 0.0023, 0.0023, 0.0026, 0.0026,         0.0024, 0.0023, 0.0024, 0.0022, 0.0021, 0.0028, 0.0028, 0.0023, 0.0022,         0.0027, 0.0021, 0.0022, 0.0022, 0.0027, 0.0026, 0.0024, 0.0023, 0.0029,         0.0026, 0.0028, 0.0029, 0.0027, 0.0023, 0.0026, 0.0025, 0.0022, 0.0024,         0.0025, 0.0023, 0.0029, 0.0026, 0.0026, 0.0033, 0.0021, 0.0021, 0.0022,         0.0021, 0.0022, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021,         0.0024, 0.0021, 0.0021],        [0.0024, 0.0026, 0.0024, 0.0024, 0.0023, 0.0017, 0.0024, 0.0029, 0.0018,         0.0018, 0.0029, 0.0030, 0.0023, 0.0019, 0.0023, 0.0020, 0.0020, 0.0020,         0.0019, 0.0020, 0.0019, 0.0020, 0.0024, 0.0020, 0.0020, 0.0023, 0.0022,         0.0020, 0.0020, 0.0020, 0.0019, 0.0018, 0.0024, 0.0024, 0.0020, 0.0019,         0.0023, 0.0018, 0.0019, 0.0019, 0.0023, 0.0023, 0.0020, 0.0020, 0.0025,         0.0022, 0.0024, 0.0025, 0.0023, 0.0020, 0.0022, 0.0022, 0.0019, 0.0021,         0.0021, 0.0020, 0.0025, 0.0022, 0.0022, 0.0028, 0.0018, 0.0018, 0.0018,         0.0018, 0.0019, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0019, 0.0018,         0.0020, 0.0018, 0.0018]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ^\n",
      "SyntaxError: invalid syntax\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marluxiaboss/anaconda3/envs/fewshotbench/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_vars.py\", line 624, in change_attr_expression\n",
      "    value = eval(expression, frame.f_globals, frame.f_locals)\n",
      "  File \"<string>\", line 1\n",
      "    tensor([[0.0036, 0.0038, 0.0035, 0.0035, 0.0034],        [0.0025, 0.0035, 0.0043, 0.0026, 0.0026],        [0.0043, 0.0044, 0.0034, 0.0028, 0.0034],        [0.0030, 0.0030, 0.0030, 0.0028, 0.0029],        [0.0028, 0.0029, 0.0035, 0.0029, 0.0029],        [0.0033, 0.0033, 0.0030, 0.0029, 0.0030],        [0.0027, 0.0027, 0.0035, 0.0035, 0.0029],        [0.0028, 0.0034, 0.0027, 0.0028, 0.0027],        [0.0034, 0.0033, 0.0030, 0.0029, 0.0037],        [0.0033, 0.0036, 0.0037, 0.0033, 0.0029],        [0.0032, 0.0032, 0.0027, 0.0030, 0.0031],        [0.0029, 0.0036, 0.0033, 0.0032, 0.0042],        [0.0026, 0.0026, 0.0027, 0.0027, 0.0027],        [0.0026, 0.0027, 0.0026, 0.0027, 0.0027],        [0.0027, 0.0026, 0.0030, 0.0026, 0.0027],        [0.0029, 0.0031, 0.0028, 0.0028, 0.0028],        [0.0020, 0.0028, 0.0035, 0.0021, 0.0021],        [0.0035, 0.0036, 0.0027, 0.0023, 0.0027],        [0.0024, 0.0024, 0.0024, 0.0022, 0.0023],        [0.0023, 0.0024, 0.0028, 0.0023, 0.0023],        [0.0027, 0.0026, 0.0024, 0.0023, 0.0024],        [0.0022, 0.0022, 0.0028, 0.0029, 0.0024],        [0.0022, 0.0027, 0.0022, 0.0022, 0.0022],        [0.0028, 0.0027, 0.0024, 0.0024, 0.0029],        [0.0026, 0.0029, 0.0030, 0.0027, 0.0023],        [0.0026, 0.0025, 0.0022, 0.0024, 0.0025],        [0.0023, 0.0029, 0.0027, 0.0026, 0.0033],        [0.0021, 0.0021, 0.0022, 0.0022, 0.0022],        [0.0021, 0.0021, 0.0021, 0.0022, 0.0021],        [0.0022, 0.0021, 0.0024, 0.0021, 0.0021],        [0.0028, 0.0030, 0.0028, 0.0028, 0.0027],        [0.0020, 0.0028, 0.0034, 0.0021, 0.0021],        [0.0034, 0.0035, 0.0027, 0.0022, 0.0027],        [0.0024, 0.0024, 0.0023, 0.0022, 0.0023],        [0.0022, 0.0023, 0.0028, 0.0023, 0.0023],        [0.0026, 0.0026, 0.0023, 0.0023, 0.0024],        [0.0022, 0.0021, 0.0028, 0.0028, 0.0023],        [0.0022, 0.0027, 0.0021, 0.0022, 0.0022],        [0.0027, 0.0026, 0.0024, 0.0023, 0.0029],        [0.0026, 0.0028, 0.0029, 0.0027, 0.0023],        [0.0026, 0.0025, 0.0022, 0.0024, 0.0024],        [0.0023, 0.0029, 0.0026, 0.0026, 0.0033],        [0.0020, 0.0021, 0.0021, 0.0021, 0.0022],        [0.0021, 0.0021, 0.0021, 0.0021, 0.0021],        [0.0022, 0.0021, 0.0024, 0.0021, 0.0021],        [0.0028, 0.0030, 0.0028, 0.0028, 0.0027],        [0.0020, 0.0028, 0.0034, 0.0021, 0.0021],        [0.0034, 0.0035, 0.0027, 0.0022, 0.0027],        [0.0024, 0.0024, 0.0023, 0.0022, 0.0023],        [0.0023, 0.0023, 0.0028, 0.0023, 0.0023],        [0.0026, 0.0026, 0.0024, 0.0023, 0.0024],        [0.0022, 0.0021, 0.0028, 0.0028, 0.0023],        [0.0022, 0.0027, 0.0021, 0.0022, 0.0022],        [0.0027, 0.0026, 0.0024, 0.0023, 0.0029],        [0.0026, 0.0028, 0.0029, 0.0027, 0.0023],        [0.0026, 0.0025, 0.0022, 0.0024, 0.0025],        [0.0023, 0.0029, 0.0026, 0.0026, 0.0033],        [0.0021, 0.0021, 0.0022, 0.0021, 0.0022],        [0.0021, 0.0021, 0.0021, 0.0021, 0.0021],        [0.0022, 0.0021, 0.0024, 0.0021, 0.0021],        [0.0024, 0.0026, 0.0024, 0.0024, 0.0023],        [0.0017, 0.0024, 0.0029, 0.0018, 0.0018],        [0.0029, 0.0030, 0.0023, 0.0019, 0.0023],        [0.0020, 0.0020, 0.0020, 0.0019, 0.0020],        [0.0019, 0.0020, 0.0024, 0.0020, 0.0020],        [0.0023, 0.0022, 0.0020, 0.0020, 0.0020],        [0.0019, 0.0018, 0.0024, 0.0024, 0.0020],        [0.0019, 0.0023, 0.0018, 0.0019, 0.0019],        [0.0023, 0.0023, 0.0020, 0.0020, 0.0025],        [0.0022, 0.0024, 0.0025, 0.0023, 0.0020],        [0.0022, 0.0022, 0.0019, 0.0021, 0.0021],        [0.0020, 0.0025, 0.0022, 0.0022, 0.0028],        [0.0018, 0.0018, 0.0018, 0.0018, 0.0019],        [0.0018, 0.0018, 0.0018, 0.0018, 0.0018],        [0.0019, 0.0018, 0.0020, 0.0018, 0.0018]], device='cuda:0',       grad_fn=<ViewBackward0>)\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ^\n",
      "SyntaxError: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train_model(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fewshotbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
